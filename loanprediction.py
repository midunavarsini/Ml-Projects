# -*- coding: utf-8 -*-
"""loanprediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x0gF0sl7VbmnfVZT01j1a1tD68D9XU-J

## Business Problem:
Dream Housing Finance company deals in all home loans. They have presence across all urban, semi urban and rural areas. Customer first apply for home loan after that company validates the customer eligibility for loan. Company wants to automate the loan eligibility process based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers.
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing required Packages
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import warnings
warnings.filterwarnings("ignore")

# Read Test and Train
train=pd.read_csv("trainloan.csv")
test=pd.read_csv("testloan.csv")

# Copy of original data
train_original=train.copy()
test_original=test.copy()

# Features in the dataset
train.columns, test.columns

# Print data types for each variable
train.dtypes

# Shape of the dataset
train.shape, test.shape

"""# Univariate analysis"""

train['Loan_Status'].value_counts()

# Normalize can be set to True to print proportions instead of number
train['Loan_Status'].value_counts(normalize=True)

train['Loan_Status'].value_counts(normalize=True)
train['Loan_Status'].value_counts().plot.bar()

"""around 69% loan applications were approved

### Univariate analysis of categorical features
"""

# Visualizing categorical features
plt.figure(1)
plt.subplot(221)
train['Gender'].value_counts(normalize=True).plot.bar(figsize=(20,10), title= 'Gender')

plt.subplot(222)
train['Married'].value_counts(normalize=True).plot.bar(title= 'Married')

plt.subplot(223)
train['Dependents'].value_counts(normalize=True).plot.bar(title= 'Dependents')

plt.subplot(224)
train['Education'].value_counts(normalize=True).plot.bar(title= 'Education')

plt.show()

"""around 80% were male applicants

around 65% were married

most of the applicants didn't have any dependents

around 77% applicants are graduate
"""

# Visualizing remaining categorical features
plt.figure(1)
plt.subplot(131)
train['Self_Employed'].value_counts(normalize=True).plot.bar(figsize=(24,6), title= 'Self_Employed')

plt.subplot(132)
train['Credit_History'].value_counts(normalize=True).plot.bar(title= 'Credit_History')

plt.subplot(133)
train['Property_Area'].value_counts(normalize=True).plot.bar(title= 'Property_Area')

plt.show()

"""around 15% of applicants are self employed

around 85% applicants have repaid there loans

most of the applicant reside in Semiurban area
"""

# Checking the missing values
train.isnull().sum()

# replacing the missing values with the mode
train['Gender'].fillna(train['Gender'].mode()[0], inplace=True)
train['Married'].fillna(train['Married'].mode()[0], inplace=True)
train['Dependents'].fillna(train['Dependents'].mode()[0], inplace=True)
train['Self_Employed'].fillna(train['Self_Employed'].mode()[0], inplace=True)
train['Credit_History'].fillna(train['Credit_History'].mode()[0], inplace=True)

train['Loan_Amount_Term'].value_counts()

train['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].mode()[0], inplace=True)

# Replacing the missing value in LoanAmount based on the values of Self_Employed and Education Variable
table = train.pivot_table(values='LoanAmount', index='Self_Employed' ,columns='Education', aggfunc=np.median)

# Define function to return value of this pivot_table
def fage(x):
 return table.loc[x['Self_Employed'],x['Education']]

# Replace missing values
train['LoanAmount'].fillna(train[train['LoanAmount'].isnull()].apply(fage, axis=1), inplace=True)

train.isnull().sum()

# Similar changes in test file
test['Gender'].fillna(test['Gender'].mode()[0], inplace=True)
test['Dependents'].fillna(test['Dependents'].mode()[0], inplace=True)
test['Self_Employed'].fillna(test['Self_Employed'].mode()[0], inplace=True)
test['Credit_History'].fillna(test['Credit_History'].mode()[0], inplace=True)
test['Loan_Amount_Term'].fillna(test['Loan_Amount_Term'].mode()[0], inplace=True)
table = test.pivot_table(values='LoanAmount', index='Self_Employed' ,columns='Education', aggfunc=np.median)

# Define function to return value of this pivot_table
def fage(x):
 return table.loc[x['Self_Employed'],x['Education']]

# Replace missing values
test['LoanAmount'].fillna(test[test['LoanAmount'].isnull()].apply(fage, axis=1), inplace=True)

# Removing skewness in LoanAmount variable by log transformation
train['LoanAmount_log'] = np.log(train['LoanAmount'])
train['LoanAmount_log'].hist(bins=20)
test['LoanAmount_log'] = np.log(test['LoanAmount'])

#loan id don't have an effect on the outcome
train=train.drop('Loan_ID',axis=1)
test=test.drop('Loan_ID',axis=1)

"""Sklearn requires the target variable in a separate dataset.
so, we will drop our target variable from the train dataset and save it in another dataset."""

x = train.drop('Loan_Status',1)
y = train.Loan_Status

x=pd.get_dummies(x)
train=pd.get_dummies(train)
test=pd.get_dummies(test)

#we will use train_test_split function of sklearn to validate our predictions
from sklearn.model_selection import train_test_split

x_train,x_cv,y_train,y_cv = train_test_split(x,y, test_size=0.3, random_state=123)

"""### Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

LR=LogisticRegression()
LR.fit(x_train,y_train)

pred_cv=LR.predict(x_cv)
accuracy_score(y_cv,pred_cv)